{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce script automatise le processus de traitement des fichiers texte :\n",
    "\n",
    "Nettoyage des fichiers texte : Supprime les espaces multiples, les numéros de page, et les sauts de ligne.\n",
    "\n",
    "Segmentation des phrases : Utilise des outils NLP (stanza et spacy) pour segmenter le texte en phrases.\n",
    "\n",
    "Création d'un fichier CSV : Regroupe les phrases segmentées par langue dans un fichier CSV structuré."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os pour les opérations système (par exemple, parcourir les dossiers et créer des répertoires).\n",
    "\n",
    "re pour les opérations avec des expressions régulières (par exemple, nettoyage du texte).\n",
    "\n",
    "pandas pour la manipulation et l'analyse des données, notamment la création du fichier CSV.\n",
    "\n",
    "stanza et spacy pour le traitement du langage naturel (NLP), notamment la segmentation des phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zia/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "import stanza\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour nettoyer le texte\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"Page \\d+\", \"\", text)\n",
    "    text = re.sub(r\"\\n\", \"\", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction normalise le texte en remplaçant les espaces multiples par un seul espace, supprime les numéros de page et les sauts de ligne, puis supprime les espaces en début et fin de texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des Fichiers Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour nettoyer les fichiers texte\n",
    "def clean_files(input_folder, output_folder):\n",
    "    os.makedirs(os.path.join(output_folder, \"fichiers_clean\"), exist_ok=True)\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                input_file_path = os.path.join(root, file)\n",
    "                output_file_path = os.path.join(output_folder, \"fichiers_clean\", file)\n",
    "                with open(input_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    text = f.read()\n",
    "                clean_content = clean_text(text)\n",
    "                with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(clean_content)\n",
    "    print(\"Tous les fichiers ont été nettoyés et enregistrés dans le répertoire : '{}'.\".format(os.path.join(output_folder, \"fichiers_clean\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parcourt tous les fichiers texte dans le dossier d'entrée (input_folder).\n",
    "\n",
    "Nettoie leur contenu en utilisant la fonction clean_text.\n",
    "\n",
    "Enregistre les fichiers nettoyés dans un sous-dossier \"fichiers_clean\" du dossier de sortie (output_folder).\n",
    "\n",
    "Crée le dossier \"fichiers_clean\" s'il n'existe pas déjà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour segmenter les phrases\n",
    "def segment_sentences(text, language):\n",
    "    if language == \"ar\":\n",
    "        nlp = stanza.Pipeline(lang=\"ar\", processors=\"tokenize\", tokenize_no_ssplit=True)\n",
    "        doc = nlp(text)\n",
    "        sentences = [\" \".join([token.text for token in sentence.tokens]) for sentence in doc.sentences]\n",
    "    elif language == \"ja\":\n",
    "        nlp = spacy.load(\"ja_core_news_sm\")\n",
    "        doc = nlp(text)\n",
    "        sentences = [sent.text for sent in doc.sents]\n",
    "    elif language == \"zh\":\n",
    "        nlp = spacy.load(\"zh_core_web_sm\")\n",
    "        doc = nlp(text)\n",
    "        sentences = [sent.text for sent in doc.sents]\n",
    "    else:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        doc = nlp(text)\n",
    "        sentences = [sent.text for sent in doc.sents]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les modèles spécifiques sont utilisés pour l'arabe, le japonais et le chinois en raison de leurs structures linguistiques uniques, tandis que le modèle anglais est employé par défaut pour d'autres langues en raison de sa flexibilité et de sa robustesse.\n",
    "\n",
    "Cette fonction segmente le texte en phrases en utilisant stanza ou spacy selon la langue :\n",
    "\n",
    "Utilise stanza pour l'arabe (ar).\n",
    "\n",
    "Utilise spacy pour le japonais (ja), le chinois (zh), et les autres langues (par défaut, l'anglais)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un Fichier CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour créer un fichier CSV\n",
    "def create_csv(input_folder, output_csv):\n",
    "    data = []\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            parts = file_name.split(\"_\")\n",
    "            if len(parts) >= 2:\n",
    "                language = parts[1].split(\".\")[0]\n",
    "                with open(os.path.join(input_folder, file_name), \"r\", encoding=\"utf-8\") as file:\n",
    "                    text = file.read()\n",
    "                sentences = segment_sentences(text, language)\n",
    "                data.extend([(language, sentence) for sentence in sentences])\n",
    "    df = pd.DataFrame(data, columns=[\"labels\", \"text\"])\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Le fichier de sortie CSV est bien généré : {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction :\n",
    "Lit tous les fichiers texte nettoyés dans le dossier d'entrée (input_folder).\n",
    "\n",
    "Segmente le texte en phrases en utilisant segment_sentences.\n",
    "Crée un DataFrame avec deux colonnes : \"labels\" (la langue) et \"text\" (les phrases segmentées).\n",
    "\n",
    "Mélange les lignes du DataFrame.\n",
    "\n",
    "Enregistre le DataFrame en tant que fichier CSV dans le chemin spécifié (output_csv).\n",
    "\n",
    "Crée les répertoires nécessaires s'ils n'existent pas déjà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tous les fichiers ont été nettoyés et enregistrés dans le répertoire : './results/fichiers_clean'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:05:32 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246d728137ce4cc2a38a5405a7edac8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:05:33 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:05:33 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:05:33 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:05:33 INFO: Using device: cpu\n",
      "2024-05-19 00:05:33 INFO: Loading: tokenize\n",
      "2024-05-19 00:05:33 INFO: Loading: mwt\n",
      "2024-05-19 00:05:33 INFO: Done loading processors!\n",
      "2024-05-19 00:05:41 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f844b60f185c475c8dcc36d9e26e5205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:05:42 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:05:42 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:05:42 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:05:42 INFO: Using device: cpu\n",
      "2024-05-19 00:05:42 INFO: Loading: tokenize\n",
      "2024-05-19 00:05:42 INFO: Loading: mwt\n",
      "2024-05-19 00:05:42 INFO: Done loading processors!\n",
      "2024-05-19 00:05:49 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a5c761d5804950baff09fe4e473fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:05:50 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:05:50 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:05:50 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:05:50 INFO: Using device: cpu\n",
      "2024-05-19 00:05:50 INFO: Loading: tokenize\n",
      "2024-05-19 00:05:50 INFO: Loading: mwt\n",
      "2024-05-19 00:05:50 INFO: Done loading processors!\n",
      "2024-05-19 00:05:55 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c160562d76442a88f199292fda113d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:05:55 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:05:55 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:05:55 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:05:55 INFO: Using device: cpu\n",
      "2024-05-19 00:05:55 INFO: Loading: tokenize\n",
      "2024-05-19 00:05:55 INFO: Loading: mwt\n",
      "2024-05-19 00:05:55 INFO: Done loading processors!\n",
      "2024-05-19 00:06:04 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338b96265a914d749ddebd62f7d31820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:06:04 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:06:04 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:06:04 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:06:04 INFO: Using device: cpu\n",
      "2024-05-19 00:06:04 INFO: Loading: tokenize\n",
      "2024-05-19 00:06:04 INFO: Loading: mwt\n",
      "2024-05-19 00:06:04 INFO: Done loading processors!\n",
      "2024-05-19 00:06:16 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e703b02f2db40c79b7e40ff4ef16576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:06:16 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:06:16 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:06:16 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:06:16 INFO: Using device: cpu\n",
      "2024-05-19 00:06:16 INFO: Loading: tokenize\n",
      "2024-05-19 00:06:16 INFO: Loading: mwt\n",
      "2024-05-19 00:06:16 INFO: Done loading processors!\n",
      "2024-05-19 00:06:39 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df82b938be8a49328a9bf823ff686cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:06:39 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:06:39 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:06:39 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:06:39 INFO: Using device: cpu\n",
      "2024-05-19 00:06:39 INFO: Loading: tokenize\n",
      "2024-05-19 00:06:39 INFO: Loading: mwt\n",
      "2024-05-19 00:06:39 INFO: Done loading processors!\n",
      "2024-05-19 00:06:39 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7a6eeec45d45e1a1198e3b1d3f2394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:06:40 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:06:40 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:06:40 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:06:40 INFO: Using device: cpu\n",
      "2024-05-19 00:06:40 INFO: Loading: tokenize\n",
      "2024-05-19 00:06:40 INFO: Loading: mwt\n",
      "2024-05-19 00:06:40 INFO: Done loading processors!\n",
      "2024-05-19 00:06:49 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0f4d99d4d94090aa5756bf72f9f90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:06:49 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:06:49 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:06:49 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:06:49 INFO: Using device: cpu\n",
      "2024-05-19 00:06:49 INFO: Loading: tokenize\n",
      "2024-05-19 00:06:49 INFO: Loading: mwt\n",
      "2024-05-19 00:06:49 INFO: Done loading processors!\n",
      "2024-05-19 00:06:53 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc29a1ebf87475f8a5128e31c54e0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:06:53 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:06:53 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:06:53 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:06:53 INFO: Using device: cpu\n",
      "2024-05-19 00:06:53 INFO: Loading: tokenize\n",
      "2024-05-19 00:06:53 INFO: Loading: mwt\n",
      "2024-05-19 00:06:53 INFO: Done loading processors!\n",
      "2024-05-19 00:07:03 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b4eda9295c46ac977caa5caed1121d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:07:03 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:07:03 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:07:03 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:07:03 INFO: Using device: cpu\n",
      "2024-05-19 00:07:03 INFO: Loading: tokenize\n",
      "2024-05-19 00:07:03 INFO: Loading: mwt\n",
      "2024-05-19 00:07:03 INFO: Done loading processors!\n",
      "2024-05-19 00:07:05 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7177609553e46558bb6a6e655e0cf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:07:05 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:07:05 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:07:05 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:07:05 INFO: Using device: cpu\n",
      "2024-05-19 00:07:05 INFO: Loading: tokenize\n",
      "2024-05-19 00:07:05 INFO: Loading: mwt\n",
      "2024-05-19 00:07:05 INFO: Done loading processors!\n",
      "2024-05-19 00:07:07 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26079b302a274fc78dc6fdfb0c30345a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:07:08 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:07:08 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:07:08 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:07:08 INFO: Using device: cpu\n",
      "2024-05-19 00:07:08 INFO: Loading: tokenize\n",
      "2024-05-19 00:07:08 INFO: Loading: mwt\n",
      "2024-05-19 00:07:08 INFO: Done loading processors!\n",
      "2024-05-19 00:07:20 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749bc5ebe9c745368fb8d17fe9446607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:07:21 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:07:21 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:07:21 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:07:21 INFO: Using device: cpu\n",
      "2024-05-19 00:07:21 INFO: Loading: tokenize\n",
      "2024-05-19 00:07:21 INFO: Loading: mwt\n",
      "2024-05-19 00:07:21 INFO: Done loading processors!\n",
      "2024-05-19 00:07:21 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed0fa23871c49e48efa1c1583e19188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:07:22 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:07:22 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:07:22 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:07:22 INFO: Using device: cpu\n",
      "2024-05-19 00:07:22 INFO: Loading: tokenize\n",
      "2024-05-19 00:07:22 INFO: Loading: mwt\n",
      "2024-05-19 00:07:22 INFO: Done loading processors!\n",
      "2024-05-19 00:07:23 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bec983c4f84f9c91b50ac68180c987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:07:23 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:07:23 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:07:23 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:07:23 INFO: Using device: cpu\n",
      "2024-05-19 00:07:23 INFO: Loading: tokenize\n",
      "2024-05-19 00:07:23 INFO: Loading: mwt\n",
      "2024-05-19 00:07:23 INFO: Done loading processors!\n",
      "2024-05-19 00:07:24 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a92170ab8c24f4c9bb17aed1e0ab98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:07:24 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:07:24 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:07:24 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:07:24 INFO: Using device: cpu\n",
      "2024-05-19 00:07:24 INFO: Loading: tokenize\n",
      "2024-05-19 00:07:24 INFO: Loading: mwt\n",
      "2024-05-19 00:07:24 INFO: Done loading processors!\n",
      "2024-05-19 00:07:42 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05ced09f5004d64a4a2a5a8a314152d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:07:43 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:07:43 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:07:43 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:07:43 INFO: Using device: cpu\n",
      "2024-05-19 00:07:43 INFO: Loading: tokenize\n",
      "2024-05-19 00:07:43 INFO: Loading: mwt\n",
      "2024-05-19 00:07:43 INFO: Done loading processors!\n",
      "2024-05-19 00:07:57 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5eab29fd7cc4302a2678d7f3d21e617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:07:58 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:07:58 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:07:58 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:07:58 INFO: Using device: cpu\n",
      "2024-05-19 00:07:58 INFO: Loading: tokenize\n",
      "2024-05-19 00:07:58 INFO: Loading: mwt\n",
      "2024-05-19 00:07:58 INFO: Done loading processors!\n",
      "2024-05-19 00:07:59 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87c344431264a53b25a06d44877ce5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 00:07:59 INFO: Downloaded file to /home/zia/stanza_resources/resources.json\n",
      "2024-05-19 00:07:59 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-19 00:07:59 INFO: Loading these models for language: ar (Arabic):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | padt    |\n",
      "| mwt       | padt    |\n",
      "=======================\n",
      "\n",
      "2024-05-19 00:07:59 INFO: Using device: cpu\n",
      "2024-05-19 00:07:59 INFO: Loading: tokenize\n",
      "2024-05-19 00:07:59 INFO: Loading: mwt\n",
      "2024-05-19 00:07:59 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier de sortie CSV est bien généré : ./results/CSV/result.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_folder = \"../raw/results/\"\n",
    "    output_folder = \"./results\"\n",
    "    clean_files(input_folder, output_folder)\n",
    "    create_csv(os.path.join(output_folder, \"fichiers_clean\"), os.path.join(output_folder, \"CSV\", \"result.csv\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction principale du script :\n",
    "\n",
    "Spécifie les chemins des dossiers d'entrée (input_folder) et de sortie (output_folder).\n",
    "\n",
    "Appelle clean_files pour nettoyer les fichiers texte.\n",
    "\n",
    "Appelle create_csv pour segmenter les phrases et créer le fichier CSV.\n",
    "\n",
    "Exécution Conditionnelle : Si le script est exécuté directement, la fonction main est appelée, ce qui lance le processus complet de nettoyage, segmentation et création du fichier CSV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
